{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dc3a8d17",
      "metadata": {
        "id": "dc3a8d17"
      },
      "source": [
        "### 다양한 모델을 결합한 앙상블\n",
        "- 앙상블\n",
        "- 다수결 두표 앙상블(Voting)\n",
        "- 배깅(Bagging)\n",
        "- 에이다부스트(AdaBost)\n",
        "- 그레이던트 부스팅 & XGBoost\n",
        "- 모델성능 평가 및 비교"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20709728",
      "metadata": {
        "id": "20709728"
      },
      "source": [
        "- 단일모델의 한계\n",
        "    - 과대적합(Overfitting) :  학습데이터에 너무 맞춰져있어서 새로운 데이터에 대한 성능저하\n",
        "    - 과소적합(Underfitting) : 모델이 너무 단순해서 제대로 학습이 안됨\n",
        "    - 높은 분산(Hight Variance) : 학습데이터가 조금만 바꿔도 모델이 크게 달라지는 현상\n",
        "    - 높은 편향(High Bias) :  모델이 진짜 패턴을 포착하지 못함\n",
        "- 앙상블( 집단지성 )    \n",
        "    - 배깅   :  같은 알고리즘, 다른 데이터셋(부트스트랩)     RandomFores            분산 감소\n",
        "    - 부스팅 :  순차적으로 약한 학습기를 강화              AdaBoost ,XGBoost        편향 감소    \n",
        "    - 스태깅 :  다른알고리즘을 메타 모델로 학습                                     일반화 성능"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f70cb70",
      "metadata": {
        "id": "9f70cb70"
      },
      "source": [
        "- Voting\n",
        "    - Hard Voting : 다수결 투표\n",
        "        A : 고양이\n",
        "        B : 강아지\n",
        "        C : 고양이\n",
        "    - Soft Voting : 가중치 투표 - 확률을 보고 결정  보통 Hard Voing 보다 성능이 좋음\n",
        "        고양이, 강아지\n",
        "        A : (0.9,0.1)\n",
        "        B : (0.4,0.6)\n",
        "        C : (0.6,0.2)\n",
        "        평균확률 :   ,  \n",
        "- Bagging( Bagging - Bootstrap Aggregation)\n",
        "    - Bootstrap : 원본 데이터 1000 이면 중복을 허용해서 1000뽑아 훈련세트1를 만듦 ....\n",
        "    - Aggregation\n",
        "        - 순차적으로 학습을 하고난후 여러개의 모델들을  투표(Voting)해서 최종결론\n",
        "    - 대표모델은 RandomForest\n",
        "    - 효과 : 과적합을 방지 즉 모델의 분산을 줄여줌\n",
        "- Bosting\n",
        "    - 모델들이 순서대로 학습, 앞 모델의 실수를 뒷 모델이 보완\n",
        "        - 모델1 전체 데이터로 학습하고 예측\n",
        "        - 모델1 틀린 문제를 찾는다\n",
        "        - 틀린문제를 더 높은 가중치(중요도)를 부여\n",
        "        - 모델2 틀리기 쉬운문제들을 좀더 학습\n",
        "        - 모델2 틀린 문제를 찾는다\n",
        "        - 모델3 모델1+2가 틀린문제에 집중 -- 가중치 부여\n",
        "        - 반복\n",
        "    - 결론\n",
        "        - 예측을 합친다 성적이 더 좋은 모델의 가중치를 부여해서 최종 결론\n",
        "        - 편향을 줄여준다 Bias\n",
        "- 스태킹\n",
        "    - 1 base model : 여러개의 모델을 훈련\n",
        "    - 2 meta model\n",
        "        - 1단계 모델들이 예측한 값들을 모음\n",
        "        - 예측한 값을 훈련데이터(특성)로 사용\n",
        "    - 결론\n",
        "        새로운데이터를 최종모델(Meta-Model)(예 로지스틱회귀)를 이용해서 결론을 도출\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b570433d",
      "metadata": {
        "id": "b570433d"
      },
      "outputs": [],
      "source": [
        "# 데이터 생성\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "\n",
        "X,y =  make_classification(n_samples=500, n_features=2,random_state=42,n_redundant=0,n_clusters_per_class=1)\n",
        "np.unique(y,return_counts=True), X.shape\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "# 개별모델 생성 학습\n",
        "lr = LogisticRegression(random_state=42)\n",
        "svm = SVC(random_state=42)\n",
        "knn = KNeighborsClassifier()\n",
        "lr.fit(x_train,y_train) ; svm.fit(x_train,y_train) ; knn.fit(x_train,y_train)\n",
        "\n",
        "\n",
        "# 보팅 앙상블\n",
        "voting_hard = VotingClassifier(estimators=[('lr',lr),('svm',svm),('knn',knn)],voting='hard')\n",
        "voting_soft = VotingClassifier(estimators=[('lr',lr),('svm',svm),('knn',knn)],voting='soft')\n",
        "\n",
        "voting_hard.fit(x_train, y_train)\n",
        "voting_soft.fit(x_train, y_train)\n",
        "\n",
        "models  = [\n",
        "    ('lr',lr),\n",
        "    ('svm',svm),\n",
        "    ('knn',knn),\n",
        "    ('voting_hard',voting_hard),\n",
        "    ('voting_soft',voting_soft)\n",
        "\n",
        "           ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56f54224",
      "metadata": {
        "id": "56f54224"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}