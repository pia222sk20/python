{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13748541",
   "metadata": {},
   "source": [
    "##### DNN  CNN\n",
    "    - 독립적인 정보\n",
    "    - 입력(x) 간의 순서나 연관성을 고려하지 않는다\n",
    "##### 시계열 : 시간의 연속적인 흐름\n",
    "    - 시계열 데이터 : 날씨, 주식, 문장 --> 순서가 중요한 데이터    \n",
    "##### RNN\n",
    "    - 순환하는 구조\n",
    "        - 시점1 (월요일):맑음(x1) 정보가 RNN에 들어온다 -> RNN 날씨가 맑았음(h1) 이라는 요약본을생성\n",
    "        - 시점2 (화요일):흐림(x2) ->RNN 새로운정보(흐림,x2) + 어제의기억(맑았음, h1) 함께 고려 해서\n",
    "            어제 맑았는데 오늘 흐림 h2 이라는 새로운 요약본을 생성\n",
    "        - 시점3 (수요일):비(x3)->RNN 새로운정보(비,x3) 정보와  + 어제의기억(어제 맑았는데 오늘 흐림 h2 )\n",
    "            새로운 상태 h3\n",
    "        - 반복\n",
    "    - 알고리즘\n",
    "        - 각 시점(time step)에서  1.현재의 입력 과 2 과거의기억(hidden state ht-1) 받아서 \n",
    "        3. 현재의 결과물과  4 다음시점으로 넘겨줄 최신기억 ht 을 생성\n",
    "        - ht 기억이 시계열 데이터의 맥락(Context) 저장하는 역활\n",
    "    - 장점\n",
    "        - 순서가 있는 데이터의 맥락을 학습\n",
    "    - 한계\n",
    "        - 기억력이 생각보다 짧다\n",
    "        - 시계열 데이터가 길어지면(예 100단계전의 정보)\n",
    "        - 이전정보가 소실되거나 반대로 너무 강해져서 폭주가 되서 제대로 학습이 안된다. \n",
    "        - 장기 기억 의존성 문제( Long-Term Dependency Problem)\n",
    "##### LSTM & GRU\n",
    "    - LSTM(Long Short-Term Memory) : RNN 내부에 게이트(Gate) 복잡한 장치 -> 잊고, 기억할 정보를 관리\n",
    "    - GRU(Gated Recurrent Unit) : LSTM 구조를 좀더  단순화시킨 모델, LSTM성능은 비슷, 속도는 빠르다\n",
    "##### RNN 핵심수식\n",
    "    - 은닉상태 계산\n",
    "        - h1 = tanh(wxht-1 + wxt - bh)\n",
    "    - 출력계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e34ccf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>120</td>\n",
       "      <td>123</td>\n",
       "      <td>118</td>\n",
       "      <td>13181000</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-17</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>122</td>\n",
       "      <td>17284900</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-18</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "      <td>118</td>\n",
       "      <td>17948100</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-21</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>116</td>\n",
       "      <td>11670000</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-22</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>115</td>\n",
       "      <td>9689000</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Open  High  Low    Volume  Close\n",
       "0  2015-12-16   120   123  118  13181000    123\n",
       "1  2015-12-17   124   126  122  17284900    123\n",
       "2  2015-12-18   121   122  118  17948100    118\n",
       "3  2015-12-21   120   120  116  11670000    117\n",
       "4  2015-12-22   117   117  115   9689000    116"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/pia222sk20/python/refs/heads/main/data/time_data_train.csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c7d18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 967 entries, 0 to 966\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    967 non-null    object\n",
      " 1   Open    967 non-null    int64 \n",
      " 2   High    967 non-null    int64 \n",
      " 3   Low     967 non-null    int64 \n",
      " 4   Volume  967 non-null    int64 \n",
      " 5   Close   967 non-null    int64 \n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 45.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터셋 확인\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a2ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA - 탐색적 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "914a6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 정의\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "class StockDataSet(Dataset):\n",
    "    def __init__(self):\n",
    "        url = 'https://raw.githubusercontent.com/pia222sk20/python/refs/heads/main/data/time_data_train.csv'\n",
    "        self.csv = pd.read_csv(url)\n",
    "        data = self.csv.iloc[: , 1:-1].values\n",
    "        label = self.csv.iloc[:,-1].values.reshape(-1,1)\n",
    "        self.data = StandardScaler().fit_transform( data)\n",
    "        # 정답이 숫자 크다면 정규화가 학습에 도움이된다.\n",
    "        self.label = StandardScaler().fit_transform(label)\n",
    "        self.data = torch.Tensor(self.data)\n",
    "        self.label = torch.Tensor(self.label)\n",
    "    def __len__(self):\n",
    "        return len(self.data) - 30  # 사용가능한 배치 개수\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index: index + 30]\n",
    "        label = self.label[index + 30]\n",
    "        return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2bbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9954, -0.9828, -0.9983,  0.5097],\n",
       "         [-0.9571, -0.9545, -0.9593,  1.1445],\n",
       "         [-0.9858, -0.9923, -0.9983,  1.2471],\n",
       "         [-0.9954, -1.0111, -1.0178,  0.2759],\n",
       "         [-1.0242, -1.0394, -1.0276, -0.0305],\n",
       "         [-1.0242, -1.0206, -1.0178, -0.0869],\n",
       "         [-1.0146, -1.0206, -1.0081, -0.9831],\n",
       "         [-1.0242, -1.0394, -1.0373, -0.2262],\n",
       "         [-1.0146, -1.0111, -1.0081, -0.2672],\n",
       "         [-1.0050, -1.0206, -1.0178, -0.2686],\n",
       "         [-1.0337, -1.0394, -1.0373, -0.0949],\n",
       "         [-1.1008, -1.1055, -1.1251,  1.6875],\n",
       "         [-1.0912, -1.0961, -1.1154,  1.2033],\n",
       "         [-1.1391, -1.0300, -1.1251,  3.5826],\n",
       "         [-1.0337, -0.9923, -1.0569,  3.6741],\n",
       "         [-1.0337, -1.0300, -1.0666,  1.2655],\n",
       "         [-1.0721, -1.0394, -1.0666,  1.8616],\n",
       "         [-1.0337, -1.0300, -1.0276,  0.8117],\n",
       "         [-1.0529, -1.0678, -1.1251,  2.3259],\n",
       "         [-1.1295, -1.1149, -1.1642,  2.1315],\n",
       "         [-1.1678, -1.1432, -1.1544,  1.5298],\n",
       "         [-1.1199, -1.1055, -1.1154,  3.9968],\n",
       "         [-1.1008, -1.1055, -1.2032,  6.6709],\n",
       "         [-1.1104, -1.1149, -1.1544,  3.2704],\n",
       "         [-1.1391, -1.1527, -1.1837,  2.6198],\n",
       "         [-1.1870, -1.1716, -1.1837,  1.6142],\n",
       "         [-1.1870, -1.1904, -1.2227,  1.8869],\n",
       "         [-1.2157, -1.2187, -1.2617,  2.4241],\n",
       "         [-1.2445, -1.2470, -1.2715,  2.2703],\n",
       "         [-1.2636, -1.2565, -1.2617,  1.6363]]),\n",
       " tensor([-1.2452]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class StockRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StockRNN,self).__init__()\n",
    "        # (30일, 배치16개 , 각 입력의 특성 4개)  batch_first = False\n",
    "        # (배치16개, 30일 각 입력의 특성 4) batch_first = True\n",
    "        self.rnn = nn.RNN(input_size=+4, hidden_size=8,num_layers=5,batch_first=True)\n",
    "        # 출력 (batch, 30 , 8)\n",
    "        self.fc1 = nn.Linear(30*8,64)\n",
    "        self.fc2 = nn.Linear(64,1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,x,ho):\n",
    "        x,hn =  self.rnn(x,ho)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
