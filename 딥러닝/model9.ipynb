{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2ebe12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀\n",
    "# 출력의 개수를 1개로\n",
    "# 손실함수를 MSE나 기타 등등..\n",
    "# 데이터셋 과 데이터 로드를 커스텀하게 정의해서 사용\n",
    "# 나머지는 동일한 패턴으로 ... 학습 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bcc8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f19f5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 데이터 프레임\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "class BostonDataSet(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1,1)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a468c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = BostonDataSet(data, target)  # 데이터를 X, y 를 한쌍으로 묶어\n",
    "X_train_loader = DataLoader(X_dataset ,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a834d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 모델 정의\n",
    "import torch.nn as nn\n",
    "class BostonRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(BostonRegression,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fabfe71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "model = BostonRegression(data.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optim = Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8a23471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch : 1/100: 100%|██████████| 16/16 [00:00<00:00, 297.10it/s, loss=129.2964]\n",
      "epoch : 2/100: 100%|██████████| 16/16 [00:00<00:00, 249.10it/s, loss=73.2135]\n",
      "epoch : 3/100: 100%|██████████| 16/16 [00:00<00:00, 334.17it/s, loss=54.0207]\n",
      "epoch : 4/100: 100%|██████████| 16/16 [00:00<00:00, 328.43it/s, loss=54.7681]\n",
      "epoch : 5/100: 100%|██████████| 16/16 [00:00<00:00, 291.92it/s, loss=38.7916]\n",
      "epoch : 6/100: 100%|██████████| 16/16 [00:00<00:00, 300.99it/s, loss=84.1771]\n",
      "epoch : 7/100: 100%|██████████| 16/16 [00:00<00:00, 398.64it/s, loss=35.0926]\n",
      "epoch : 8/100: 100%|██████████| 16/16 [00:00<00:00, 298.26it/s, loss=83.4131]\n",
      "epoch : 9/100: 100%|██████████| 16/16 [00:00<00:00, 193.38it/s, loss=53.8679]\n",
      "epoch : 10/100: 100%|██████████| 16/16 [00:00<00:00, 391.93it/s, loss=38.1309]\n",
      "epoch : 11/100: 100%|██████████| 16/16 [00:00<00:00, 378.83it/s, loss=41.9594]\n",
      "epoch : 12/100: 100%|██████████| 16/16 [00:00<00:00, 404.61it/s, loss=32.3253]\n",
      "epoch : 13/100: 100%|██████████| 16/16 [00:00<00:00, 384.13it/s, loss=18.7241]\n",
      "epoch : 14/100: 100%|██████████| 16/16 [00:00<00:00, 362.97it/s, loss=61.7788]\n",
      "epoch : 15/100: 100%|██████████| 16/16 [00:00<00:00, 350.48it/s, loss=60.5408]\n",
      "epoch : 16/100: 100%|██████████| 16/16 [00:00<00:00, 375.41it/s, loss=66.0687]\n",
      "epoch : 17/100: 100%|██████████| 16/16 [00:00<00:00, 357.19it/s, loss=58.5173]\n",
      "epoch : 18/100: 100%|██████████| 16/16 [00:00<00:00, 422.59it/s, loss=58.4778]\n",
      "epoch : 19/100: 100%|██████████| 16/16 [00:00<00:00, 360.82it/s, loss=55.0186]\n",
      "epoch : 20/100: 100%|██████████| 16/16 [00:00<00:00, 315.19it/s, loss=41.9115]\n",
      "epoch : 21/100: 100%|██████████| 16/16 [00:00<00:00, 293.59it/s, loss=80.6544]\n",
      "epoch : 22/100: 100%|██████████| 16/16 [00:00<00:00, 355.32it/s, loss=95.3352]\n",
      "epoch : 23/100: 100%|██████████| 16/16 [00:00<00:00, 313.45it/s, loss=93.2836]\n",
      "epoch : 24/100: 100%|██████████| 16/16 [00:00<00:00, 256.47it/s, loss=27.1270]\n",
      "epoch : 25/100: 100%|██████████| 16/16 [00:00<00:00, 101.16it/s, loss=16.5243]\n",
      "epoch : 26/100: 100%|██████████| 16/16 [00:00<00:00, 377.98it/s, loss=39.5794]\n",
      "epoch : 27/100: 100%|██████████| 16/16 [00:00<00:00, 367.95it/s, loss=51.1298]\n",
      "epoch : 28/100: 100%|██████████| 16/16 [00:00<00:00, 346.41it/s, loss=28.3365]\n",
      "epoch : 29/100: 100%|██████████| 16/16 [00:00<00:00, 399.65it/s, loss=16.1906]\n",
      "epoch : 30/100: 100%|██████████| 16/16 [00:00<00:00, 366.63it/s, loss=34.5646]\n",
      "epoch : 31/100: 100%|██████████| 16/16 [00:00<00:00, 352.31it/s, loss=65.8238]\n",
      "epoch : 32/100: 100%|██████████| 16/16 [00:00<00:00, 387.79it/s, loss=44.9924]\n",
      "epoch : 33/100: 100%|██████████| 16/16 [00:00<00:00, 334.04it/s, loss=50.4520]\n",
      "epoch : 34/100: 100%|██████████| 16/16 [00:00<00:00, 375.84it/s, loss=27.7595]\n",
      "epoch : 35/100: 100%|██████████| 16/16 [00:00<00:00, 361.21it/s, loss=45.0419]\n",
      "epoch : 36/100: 100%|██████████| 16/16 [00:00<00:00, 369.33it/s, loss=30.2955]\n",
      "epoch : 37/100: 100%|██████████| 16/16 [00:00<00:00, 388.49it/s, loss=17.2126]\n",
      "epoch : 38/100: 100%|██████████| 16/16 [00:00<00:00, 315.27it/s, loss=46.3221]\n",
      "epoch : 39/100: 100%|██████████| 16/16 [00:00<00:00, 208.90it/s, loss=27.4554]\n",
      "epoch : 40/100: 100%|██████████| 16/16 [00:00<00:00, 238.93it/s, loss=54.2840]\n",
      "epoch : 41/100: 100%|██████████| 16/16 [00:00<00:00, 400.32it/s, loss=55.9003]\n",
      "epoch : 42/100: 100%|██████████| 16/16 [00:00<00:00, 358.45it/s, loss=48.5769]\n",
      "epoch : 43/100: 100%|██████████| 16/16 [00:00<00:00, 356.86it/s, loss=22.2392]\n",
      "epoch : 44/100: 100%|██████████| 16/16 [00:00<00:00, 387.48it/s, loss=20.3552]\n",
      "epoch : 45/100: 100%|██████████| 16/16 [00:00<00:00, 387.97it/s, loss=14.8257]\n",
      "epoch : 46/100: 100%|██████████| 16/16 [00:00<00:00, 345.97it/s, loss=47.3569]\n",
      "epoch : 47/100: 100%|██████████| 16/16 [00:00<00:00, 378.14it/s, loss=45.5502]\n",
      "epoch : 48/100: 100%|██████████| 16/16 [00:00<00:00, 325.31it/s, loss=13.7540]\n",
      "epoch : 49/100: 100%|██████████| 16/16 [00:00<00:00, 363.60it/s, loss=52.5522]\n",
      "epoch : 50/100: 100%|██████████| 16/16 [00:00<00:00, 382.70it/s, loss=34.4210]\n",
      "epoch : 51/100: 100%|██████████| 16/16 [00:00<00:00, 272.81it/s, loss=57.5406]\n",
      "epoch : 52/100: 100%|██████████| 16/16 [00:00<00:00, 341.88it/s, loss=47.6582]\n",
      "epoch : 53/100: 100%|██████████| 16/16 [00:00<00:00, 367.91it/s, loss=17.8104]\n",
      "epoch : 54/100: 100%|██████████| 16/16 [00:00<00:00, 367.08it/s, loss=15.6698]\n",
      "epoch : 55/100: 100%|██████████| 16/16 [00:00<00:00, 370.78it/s, loss=14.4991]\n",
      "epoch : 56/100: 100%|██████████| 16/16 [00:00<00:00, 392.14it/s, loss=22.4400]\n",
      "epoch : 57/100: 100%|██████████| 16/16 [00:00<00:00, 324.39it/s, loss=11.5549]\n",
      "epoch : 58/100: 100%|██████████| 16/16 [00:00<00:00, 376.62it/s, loss=43.4141]\n",
      "epoch : 59/100: 100%|██████████| 16/16 [00:00<00:00, 263.75it/s, loss=25.4823]\n",
      "epoch : 60/100: 100%|██████████| 16/16 [00:00<00:00, 355.06it/s, loss=31.7191]\n",
      "epoch : 61/100: 100%|██████████| 16/16 [00:00<00:00, 372.54it/s, loss=18.5527]\n",
      "epoch : 62/100: 100%|██████████| 16/16 [00:00<00:00, 261.98it/s, loss=25.0326]\n",
      "epoch : 63/100: 100%|██████████| 16/16 [00:00<00:00, 411.99it/s, loss=15.0237]\n",
      "epoch : 64/100: 100%|██████████| 16/16 [00:00<00:00, 351.06it/s, loss=25.4834]\n",
      "epoch : 65/100: 100%|██████████| 16/16 [00:00<00:00, 142.82it/s, loss=19.2022]\n",
      "epoch : 66/100: 100%|██████████| 16/16 [00:00<00:00, 403.06it/s, loss=12.1169]\n",
      "epoch : 67/100: 100%|██████████| 16/16 [00:00<00:00, 360.98it/s, loss=41.5499]\n",
      "epoch : 68/100: 100%|██████████| 16/16 [00:00<00:00, 399.65it/s, loss=19.6550]\n",
      "epoch : 69/100: 100%|██████████| 16/16 [00:00<00:00, 361.31it/s, loss=20.1756]\n",
      "epoch : 70/100: 100%|██████████| 16/16 [00:00<00:00, 351.83it/s, loss=42.0282]\n",
      "epoch : 71/100: 100%|██████████| 16/16 [00:00<00:00, 364.69it/s, loss=35.2835]\n",
      "epoch : 72/100: 100%|██████████| 16/16 [00:00<00:00, 348.90it/s, loss=15.0504]\n",
      "epoch : 73/100: 100%|██████████| 16/16 [00:00<00:00, 359.57it/s, loss=36.2578]\n",
      "epoch : 74/100: 100%|██████████| 16/16 [00:00<00:00, 372.56it/s, loss=14.6003]\n",
      "epoch : 75/100: 100%|██████████| 16/16 [00:00<00:00, 366.43it/s, loss=27.2111]\n",
      "epoch : 76/100: 100%|██████████| 16/16 [00:00<00:00, 362.11it/s, loss=22.8540]\n",
      "epoch : 77/100: 100%|██████████| 16/16 [00:00<00:00, 362.96it/s, loss=12.3413]\n",
      "epoch : 78/100: 100%|██████████| 16/16 [00:00<00:00, 358.85it/s, loss=25.1002]\n",
      "epoch : 79/100: 100%|██████████| 16/16 [00:00<00:00, 348.65it/s, loss=37.1874]\n",
      "epoch : 80/100: 100%|██████████| 16/16 [00:00<00:00, 355.81it/s, loss=34.3595]\n",
      "epoch : 81/100: 100%|██████████| 16/16 [00:00<00:00, 367.53it/s, loss=12.7873]\n",
      "epoch : 82/100: 100%|██████████| 16/16 [00:00<00:00, 387.45it/s, loss=31.4909]\n",
      "epoch : 83/100: 100%|██████████| 16/16 [00:00<00:00, 382.55it/s, loss=43.0778]\n",
      "epoch : 84/100: 100%|██████████| 16/16 [00:00<00:00, 255.19it/s, loss=36.3935]\n",
      "epoch : 85/100: 100%|██████████| 16/16 [00:00<00:00, 189.81it/s, loss=20.8336]\n",
      "epoch : 86/100: 100%|██████████| 16/16 [00:00<00:00, 393.78it/s, loss=52.0352]\n",
      "epoch : 87/100: 100%|██████████| 16/16 [00:00<00:00, 385.13it/s, loss=23.3611]\n",
      "epoch : 88/100: 100%|██████████| 16/16 [00:00<00:00, 352.84it/s, loss=19.1646]\n",
      "epoch : 89/100: 100%|██████████| 16/16 [00:00<00:00, 369.48it/s, loss=24.2928]\n",
      "epoch : 90/100: 100%|██████████| 16/16 [00:00<00:00, 308.03it/s, loss=24.8265]\n",
      "epoch : 91/100: 100%|██████████| 16/16 [00:00<00:00, 357.50it/s, loss=23.7882]\n",
      "epoch : 92/100: 100%|██████████| 16/16 [00:00<00:00, 329.41it/s, loss=33.1167]\n",
      "epoch : 93/100: 100%|██████████| 16/16 [00:00<00:00, 379.42it/s, loss=35.3351]\n",
      "epoch : 94/100: 100%|██████████| 16/16 [00:00<00:00, 360.60it/s, loss=26.0098]\n",
      "epoch : 95/100: 100%|██████████| 16/16 [00:00<00:00, 353.32it/s, loss=32.4984]\n",
      "epoch : 96/100: 100%|██████████| 16/16 [00:00<00:00, 360.86it/s, loss=25.6453]\n",
      "epoch : 97/100: 100%|██████████| 16/16 [00:00<00:00, 336.04it/s, loss=26.9398]\n",
      "epoch : 98/100: 100%|██████████| 16/16 [00:00<00:00, 391.45it/s, loss=11.2760]\n",
      "epoch : 99/100: 100%|██████████| 16/16 [00:00<00:00, 333.99it/s, loss=15.5949]\n",
      "epoch : 100/100: 100%|██████████| 16/16 [00:00<00:00, 401.80it/s, loss=23.9955]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 100 : avg loss : 21.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "epochs = 100\n",
    "# 학습루프\n",
    "for epoch in range(epochs):\n",
    "    tqdm_obj = tqdm(X_train_loader,desc=f'epoch : {epoch+1}/{epochs}')\n",
    "    loss_lists = 0\n",
    "    for data, label in tqdm_obj:\n",
    "        optim.zero_grad()\n",
    "        preds = model(data.to(device))\n",
    "        loss = criterion(preds, label.to(device))\n",
    "        loss_lists += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()    \n",
    "        tqdm_obj.set_postfix({'loss' : f'{loss.item():.4f}'})\n",
    "    avg_loss = loss_lists / len(X_train_loader)\n",
    "print(f'epoch : {epoch+1} : avg loss : {avg_loss:.4f}')\n",
    "        \n",
    "\n",
    "torch.save(model.state_dict(), 'bostonRegression.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "faa9c934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 16/16 [00:00<00:00, 160.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 20.909578561782837 r2 score : 0.7349367290735245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# 평가\n",
    "model.load_state_dict(torch.load('bostonRegression.pth',map_location=device,weights_only=True))\n",
    "# 예측\n",
    "# 평가 루프\n",
    "model.eval()  # 평가 모드로 전환 (dropout, batchnorm 등 비활성화)\n",
    "total_mse = 0\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "r2scores = 0\n",
    "with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "    for data, label in tqdm(X_train_loader, desc=\"Evaluating\"):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        preds = model(data)\n",
    "        r2scores += r2_score(label.cpu().detach().numpy(), preds.cpu().detach().numpy())\n",
    "        mse = criterion(preds, label)        \n",
    "        total_mse += mse.item()\n",
    "print(f\"Test Loss: {total_mse / len(X_train_loader)} r2 score : {r2scores/len(X_train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e737def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
