{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2102d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가우스 잡음 추가 함수\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# 가우스 노이즈\n",
    "# noiy_pixel = original_pixel + N(u=0, e = scale)\n",
    "# 평균 = 0 : 픽셀을 전체적으로 밝히거나 어둡게 하지 않음\n",
    "# 표준편차 = sacle-> 값이 클수록 노이즈가 강해짐\n",
    "# 0.8 - > 노이즈의 양 많고.. 숫자 일부를 흐릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2eb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.30514661, 0.833597  , 0.22960443, 0.18257816, 0.        ,\n",
       "         1.        , 1.        , 0.20515044, 1.        , 0.        ,\n",
       "         0.46448214, 0.        , 0.        , 0.05731997, 0.34666536,\n",
       "         0.84687448, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.18219875, 0.        , 0.        , 1.        ,\n",
       "         0.12021162, 1.        , 0.        ],\n",
       "        [0.88661863, 0.37573889, 0.        , 1.        , 1.        ,\n",
       "         0.07372879, 1.        , 0.        , 0.30278095, 0.        ,\n",
       "         0.16553861, 0.        , 0.23244621, 1.        , 1.        ,\n",
       "         0.1948915 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.22451731, 0.        , 0.65947007, 0.        , 0.48118014,\n",
       "         0.        , 0.24356017, 0.        ],\n",
       "        [0.        , 0.4350478 , 0.        , 0.93979288, 0.37991864,\n",
       "         1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "         0.42203193, 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.04879303, 0.58198433, 0.56845124, 0.        ,\n",
       "         0.        , 0.        , 0.48764222, 0.42477537, 0.58256513,\n",
       "         0.        , 0.54368925, 0.55934886],\n",
       "        [0.45776576, 0.08387444, 0.22924487, 0.        , 0.        ,\n",
       "         0.52449242, 0.        , 0.66932331, 0.        , 0.        ,\n",
       "         0.        , 0.56236596, 0.15789313, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.90459866, 0.        , 0.        ,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.1503056 ,\n",
       "         0.54590481, 0.        , 0.        ],\n",
       "        [0.        , 0.19491238, 0.        , 0.34862239, 0.23574559,\n",
       "         0.        , 0.        , 0.2784175 , 1.        , 0.        ,\n",
       "         0.15497024, 0.47047431, 0.        , 1.        , 0.12800113,\n",
       "         0.        , 0.        , 0.        , 0.28720938, 0.98608542,\n",
       "         0.        , 0.16491672, 0.        , 0.20319223, 0.22451953,\n",
       "         0.25763039, 0.        , 0.        ],\n",
       "        [0.04828334, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.36438333, 0.49993269, 0.04195787, 0.73379094, 1.        ,\n",
       "         0.        , 1.        , 0.17870272, 0.        , 0.76613442,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.48452351, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.29197797, 0.13063912, 0.45802586, 0.        ,\n",
       "         0.        , 0.        , 0.56398221, 0.        , 0.44928766,\n",
       "         0.30435961, 0.        , 0.        , 0.00787312, 1.        ,\n",
       "         0.        , 1.        , 0.0836295 , 0.        , 0.74341979,\n",
       "         0.        , 0.        , 0.80521449, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.07847399],\n",
       "        [0.        , 0.        , 0.        , 0.32621867, 0.85670407,\n",
       "         0.        , 0.        , 0.        , 0.6577828 , 0.96938438,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.66782634, 0.48777152, 0.        , 0.37584973,\n",
       "         0.28174743, 0.        , 0.59091022, 1.        , 0.        ,\n",
       "         0.58920678, 0.        , 0.95680929],\n",
       "        [0.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.02219967, 0.        , 0.52630972,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.6606515 , 0.75932826, 1.        , 0.        , 0.8395552 ,\n",
       "         0.        , 0.        , 0.73165715],\n",
       "        [1.        , 0.        , 0.        , 1.        , 0.47340389,\n",
       "         0.51400349, 0.3507527 , 0.        , 1.        , 0.87074921,\n",
       "         0.17036088, 0.        , 0.45118666, 0.        , 0.        ,\n",
       "         1.        , 0.58501459, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.38270617, 0.63404319, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.05484313, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.85596622, 0.1269915 , 0.        ,\n",
       "         0.        , 0.01784563, 0.        , 0.        , 0.        ,\n",
       "         0.24792637, 0.        , 1.        , 1.        , 0.40886351,\n",
       "         0.        , 0.        , 0.0199311 , 0.        , 0.        ,\n",
       "         0.        , 1.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.39650102,\n",
       "         0.        , 1.        , 0.6879091 , 0.        , 0.        ,\n",
       "         0.53856398, 0.        , 0.73418508, 0.0570347 , 0.        ,\n",
       "         0.29211826, 0.96243314, 0.        , 0.        , 0.34896979,\n",
       "         0.        , 0.76693531, 0.08193519, 0.        , 0.        ,\n",
       "         1.        , 1.        , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.44836073, 0.43644148,\n",
       "         1.        , 0.        , 0.        , 0.60095571, 0.        ,\n",
       "         0.28864895, 0.52612529, 0.        , 0.        , 0.        ,\n",
       "         0.14415099, 0.        , 0.        , 0.90589229, 0.15441961,\n",
       "         0.30568407, 0.6834966 , 0.        , 0.92577653, 0.        ,\n",
       "         0.03759359, 1.        , 0.        ],\n",
       "        [0.76247558, 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.        , 0.57862459, 0.07128406, 0.        ,\n",
       "         0.68365582, 0.        , 1.        , 0.5080983 , 0.21533233,\n",
       "         0.        , 0.        , 0.33693433, 1.        , 0.        ,\n",
       "         0.35204576, 0.60163393, 0.1304907 , 1.        , 0.11804949,\n",
       "         0.43214981, 0.        , 0.11239241],\n",
       "        [0.        , 0.        , 0.        , 0.23767355, 0.        ,\n",
       "         1.        , 0.        , 0.        , 0.296799  , 0.89760424,\n",
       "         0.12427828, 0.        , 0.0278891 , 0.93833269, 0.01895382,\n",
       "         1.        , 0.02031857, 0.45893846, 0.        , 0.46096404,\n",
       "         0.        , 0.        , 0.20869627, 0.        , 0.30102063,\n",
       "         0.30073486, 0.        , 0.43914511],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.99913408, 0.        , 0.40549703, 0.        , 0.        ,\n",
       "         0.        , 0.46829322, 1.        , 0.01851995, 0.        ,\n",
       "         0.        , 0.        , 0.59488226, 0.        , 0.        ,\n",
       "         0.93011254, 0.        , 1.        , 0.16530172, 0.        ,\n",
       "         1.        , 0.63999855, 1.        ],\n",
       "        [0.        , 0.88702253, 0.        , 0.        , 0.84963016,\n",
       "         1.        , 0.        , 0.06873183, 0.24000262, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.10247481,\n",
       "         0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "         0.54142717, 0.        , 0.11463173, 0.        , 0.10324379,\n",
       "         0.        , 0.        , 1.        ],\n",
       "        [0.        , 0.91276353, 0.91016744, 0.        , 0.        ,\n",
       "         0.        , 0.11677684, 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.18669878, 0.78474503, 0.        ,\n",
       "         0.61090672, 0.43080284, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.1253893 , 0.        , 0.        ,\n",
       "         0.78053449, 0.64355019, 0.        ],\n",
       "        [0.28429742, 0.12204913, 0.        , 0.        , 0.31304532,\n",
       "         0.        , 0.        , 0.        , 0.35328857, 0.2664965 ,\n",
       "         0.27512733, 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.47256417, 0.        , 0.        ,\n",
       "         0.        , 0.56101386, 0.        , 0.09891519, 0.        ,\n",
       "         0.49587661, 0.        , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.58567581, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.42953319, 0.        ,\n",
       "         0.        , 0.15586129, 0.91098701, 0.        , 0.        ,\n",
       "         0.        , 0.08700557, 0.24849092, 0.        , 0.80026293,\n",
       "         0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.84052148, 0.06134013],\n",
       "        [0.50760559, 0.43094956, 0.09212044, 0.08276191, 0.        ,\n",
       "         0.        , 0.52665513, 1.        , 1.        , 0.70919019,\n",
       "         0.32165696, 1.        , 1.        , 0.05087279, 0.        ,\n",
       "         0.00903655, 0.01404893, 0.        , 0.        , 0.51535215,\n",
       "         0.84888237, 0.        , 0.        , 0.        , 0.86233993,\n",
       "         0.02503755, 0.        , 0.        ],\n",
       "        [0.        , 0.57131998, 0.07003443, 0.3804123 , 0.84273829,\n",
       "         0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "         0.        , 0.29529066, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.36673796, 0.0471136 , 0.        , 0.        ,\n",
       "         0.858439  , 0.        , 0.82630018],\n",
       "        [0.        , 0.62038247, 0.465494  , 0.34410378, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.04957817,\n",
       "         0.79076959, 0.45474645, 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.10752075, 0.        , 0.81350583, 1.        ,\n",
       "         1.        , 0.42651173, 0.95704742, 0.18199493, 0.18224129,\n",
       "         1.        , 0.        , 0.17675077],\n",
       "        [0.        , 0.        , 0.18536486, 0.96272272, 0.83440246,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.039495  , 0.        , 0.        , 0.40386858,\n",
       "         0.        , 0.        , 0.        , 0.1880097 , 0.        ,\n",
       "         0.40580034, 0.        , 0.5185274 , 0.        , 0.        ,\n",
       "         0.37560686, 0.        , 0.17556553],\n",
       "        [0.        , 0.5862243 , 0.        , 0.        , 0.        ,\n",
       "         0.20490181, 0.        , 0.11862453, 1.        , 0.11061936,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.70248516, 0.91553206, 0.72579099, 0.27101651, 0.        ,\n",
       "         0.        , 0.80716974, 1.        , 0.        , 0.7500458 ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.32705674, 0.84007164, 0.54948639, 0.17149608, 0.        ,\n",
       "         0.        , 0.39054175, 0.08661343, 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.19449196, 0.        , 0.        , 0.87430089,\n",
       "         0.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "         0.50279551, 0.        , 1.        ],\n",
       "        [0.        , 0.2439563 , 0.        , 0.        , 0.14460895,\n",
       "         0.65607672, 1.        , 0.45181398, 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.        , 0.56182306, 0.        ,\n",
       "         0.05738208, 0.3392886 , 1.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.75066089, 0.15394753, 0.28436735,\n",
       "         0.        , 0.        , 0.83739071],\n",
       "        [0.56456285, 0.96679023, 0.        , 0.10943934, 0.        ,\n",
       "         0.        , 0.76924255, 0.        , 0.20903076, 0.08000384,\n",
       "         0.49671273, 1.        , 0.        , 0.        , 0.06610965,\n",
       "         0.        , 0.77259682, 0.        , 1.        , 0.51484217,\n",
       "         0.27113748, 0.87044479, 1.        , 1.        , 0.        ,\n",
       "         0.45018245, 0.45194066, 0.        ]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_data_x = np.random.normal(\n",
    "        loc = 0, scale =0.8, size = (1,28,28)\n",
    "    )\n",
    "gaussian_data_x.shape\n",
    "\n",
    "np.clip(gaussian_data_x, 0 , 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8203cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(x, scale=0.8):\n",
    "    gaussian_data_x = x +  np.random.normal(\n",
    "        loc = 0, scale =scale, size = x.shape\n",
    "    )\n",
    "    gaussian_data_x = np.clip(gaussian_data_x,0,1)  # 이미지픽셀의 값을 0과 1사이로 정규화\n",
    "    gaussian_data_x = torch.tensor(gaussian_data_x,dtype=torch.float32)\n",
    "    return gaussian_data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2856e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "traning_data = MNIST(root='./', train=True, download=True,transform=ToTensor())\n",
    "test_data = MNIST(root='./', train=False, download=True,transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a04c40a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\playdata2\\AppData\\Local\\Temp\\ipykernel_9028\\2047172819.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gaussian_data_x = x +  np.random.normal(\n",
      "C:\\Users\\playdata2\\AppData\\Local\\Temp\\ipykernel_9028\\2047172819.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gaussian_data_x = torch.tensor(gaussian_data_x,dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21027b9db90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img,label = next(iter(traning_data))\n",
    "print(img.shape)\n",
    "gaussian = gaussian_noise(img)\n",
    "img = img.permute(1,2,0)\n",
    "gaussian = gaussian.permute(1,2,0)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(gaussian,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf92f6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\playdata2\\AppData\\Local\\Temp\\ipykernel_9028\\2047172819.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gaussian_data_x = x +  np.random.normal(\n",
      "C:\\Users\\playdata2\\AppData\\Local\\Temp\\ipykernel_9028\\2047172819.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gaussian_data_x = torch.tensor(gaussian_data_x,dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "for data, label in traning_data:\n",
    "    noisy = gaussian_noise(data)\n",
    "    print(type(noisy), noisy.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a875b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 데이터셋\n",
    "from torch.utils.data.dataset import Dataset\n",
    "class Denoise(Dataset):\n",
    "    def __init__(self):\n",
    "        self.mnist = MNIST(root='./', train=True, download=True,transform=ToTensor())\n",
    "        self.data = []\n",
    "        # 잡음 입히기\n",
    "        for data, label in self.mnist:\n",
    "            noisy =  gaussian_noise(data)  # 0 ~ 1사이로 맞춤\n",
    "            self.data.append(noisy) # (1, 28, 28)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        label = self.mnist.data[index] / 255  # 원본이미지도 0 ~1 정규화\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88152369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 기본 블럭\n",
    "import torch.nn as nn\n",
    "# conv-relu-conv-relu\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel,hidden_channel):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, hidden_channel,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channel, out_channel,kernel_size=3,padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01d998db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 28, 28])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = torch.randn(1,1,28,28)\n",
    "sample_model = BasicBlock(1,20,10)\n",
    "sample_model(sample_data).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eaac5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.conv1 = BasicBlock(1,16,16)\n",
    "        self.conv2 = BasicBlock(16,8,8)\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x)) # 1,16,14,41\n",
    "        out = self.pool(self.conv2(x)) # 1, 8,7,7\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70d2cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = torch.randn(1,1,28,28)\n",
    "temp_encoder = Encoder()\n",
    "result_encoder = temp_encoder(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c151054",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.conv1 = BasicBlock(8,8,8)\n",
    "        self.conv2 = BasicBlock(8,16,16)\n",
    "        # 출력층\n",
    "        self.conv3 = nn.Conv2d(16,1,kernel_size=3,padding=1)\n",
    "\n",
    "        # 업셈플링 층\n",
    "        self.upsampling1 = nn.ConvTranspose2d(8,8,kernel_size=2, stride=2)\n",
    "        self.upsampling2 = nn.ConvTranspose2d(16,16,kernel_size=2, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.upsampling1(self.conv1(x))\n",
    "        x = self.upsampling2(self.conv2(x))\n",
    "        out = self.conv3(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3150509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Decoder()\n",
    "d(result_encoder).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f61d11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAE 오토인코더\n",
    "# 인코더와 디코더를 연결 : 인코더의 출력을 디코더의 입력으로 제공\n",
    "class CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CAE,self).__init__()\n",
    "        self.enc = Encoder()\n",
    "        self.dec = Decoder()\n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        x = self.dec(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "371118f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\playdata2\\AppData\\Local\\Temp\\ipykernel_9028\\2047172819.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gaussian_data_x = x +  np.random.normal(\n",
      "C:\\Users\\playdata2\\AppData\\Local\\Temp\\ipykernel_9028\\2047172819.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gaussian_data_x = torch.tensor(gaussian_data_x,dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim.adam import Adam\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.optim.adam import Adam\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "train_dataset = Denoise()\n",
    "train_loader = DataLoader(train_dataset,batch_size=32)\n",
    "model = CAE().to(device)\n",
    "optim = Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5818c0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), torch.Size([28, 28]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, label = next(iter(train_dataset))\n",
    "data.size(), label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "285d4e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, label = next(iter(train_loader))\n",
    "data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc9ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]c:\\Users\\playdata2\\miniconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([32, 28, 28])) that is different to the input size (torch.Size([32, 1, 28, 28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 1875/1875 [00:55<00:00, 33.91it/s, loss=0.0661]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m pred = model(data)\n\u001b[32m      8\u001b[39m loss = criterian(pred, label)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m optim.step()\n\u001b[32m     12\u001b[39m loop.set_postfix({\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m:\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\playdata2\\miniconda3\\envs\\deep\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\playdata2\\miniconda3\\envs\\deep\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\playdata2\\miniconda3\\envs\\deep\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "criterian = nn.MSELoss()\n",
    "for epoch in range(2):\n",
    "    loop = tqdm(train_loader)\n",
    "    for data, label in loop:\n",
    "        optim.zero_grad()\n",
    "        data,label = data.to(device), label.to(device)\n",
    "        pred = model(data)\n",
    "        loss = criterian(pred, label)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        loop.set_postfix({'loss':f'{loss.item():.4f}'})\n",
    "torch.save(model.state_dict(), 'CAE.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687dc33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
